{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Sep  5 11:14:42 2019\n",
    "\n",
    "@author: 彭钊\n",
    "\n",
    "数据读取和窗口化标准化等必要预处理（本版本已完成地震数据格式（seed、mseed等）和压缩文本格式的读取，更多数据格式有待后续版本更新）\n",
    "\n",
    "所需额外扩展包：obspy、preprocess（自编）、numpy、h5py、matplotlib、sklearn、zipfile、os\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取地震数据格式（seed、mseed等）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import obspy\n",
    "from obspy.core import UTCDateTime\n",
    "from preprocess import *\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 读取数据\n",
    "- **obspy**可以将各种格式的地震数据（例如SAC，MiniSEED，GSE2，SEISAN，Q等）使用**read（）**函数的对象导入到**Stream**对象中。\n",
    "- **Stream**类似一个包含多个**Trace**对象（例如无间隙连续时间序列和相关的对象头/元信息）的列表。\n",
    "+ 每个**Trace**对象都有一个名为**data**的属性，对应实际时间序列的NumPy ndarray，以及**stats**属性（Stats对象是一个包含所有元信息的字典）。\n",
    "- **Stats**中的starttime和endtime也都是UTCDateTime对象。\n",
    "```\n",
    ">>> import obspy\n",
    ">>> st = obspy.read('http://examples.obspy.org/RJOB_061005_072159.mseed')\n",
    ">>> print(st)\n",
    ">>> tr = st[0]\n",
    ">>> print(tr)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "st = obspy.read(r\"F:\\星火\\数据\\云南盈江地震\\20140604.HS.QKT.seed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr = st[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- 在每个**Trace**中可通过**stats**关键词对地震元数据（描述实际波形数据的数据）进行访问\n",
    "```\n",
    ">>> print(tr.stats)\n",
    "```\n",
    "- 在每个**Trace**中可以通过**data**关键词对实际波形数据进行检索\n",
    "```\n",
    ">>> tr.data\n",
    "array([-38,  12,  -4, ..., -14,  -3,  -9])\n",
    ">>> tr.data[0:3]\n",
    "array([-38,  12,  -4])\n",
    ">>> len(tr)\n",
    "36000\n",
    "```\n",
    "- **Stream**对象提供了一个用于快速预览波形的`plot（）`方法\n",
    "```\n",
    ">>> st.plot()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(tr.stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "st.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 同一台站多日数据合并\n",
    "先把台站多日数据读取到一个**Stream**对象中，然后用**merge**方法合并，`fill_value=0`为填充值。\n",
    "```\n",
    ">>> st = obspy.read(r\"***.seed\")\n",
    ">>> st += obspy.read(r\"***.seed\")\n",
    "*\n",
    "*\n",
    "*\n",
    ">>> st.merge(method=1,fill_value=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### UTCDateTime（世界标准时间数据）\n",
    "ObsPy中的所有绝对时间值均由UTCDateTime类一致处理。因为精度问题它基于高精度POSIX时间戳，而不是Python datetime类。\n",
    "```\n",
    ">>> from obspy.core import UTCDateTime\n",
    ">>> UTCDateTime(\"2012-09-07T12:15:00\")\n",
    "UTCDateTime(2012, 9, 7, 12, 15)\n",
    ">>> UTCDateTime(2012, 9, 7, 12, 15, 0)\n",
    "UTCDateTime(2012, 9, 7, 12, 15)\n",
    ">>> UTCDateTime(1347020100.0)\n",
    "UTCDateTime(2012, 9, 7, 12, 15)\n",
    "```\n",
    "处理时间差\n",
    "```\n",
    ">>> time = UTCDateTime(\"2012-09-07T12:15:00\")\n",
    ">>> print(time + 3600)\n",
    "2012-09-07T13:15:00.000000Z\n",
    ">>> time2 = UTCDateTime(2012, 1, 1)\n",
    ">>> print(time - time2)\n",
    "21644100.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 波形绘制：根据给定的时间戳绘制波形图\n",
    "```\n",
    ">>> dt = UTCDateTime(2014, 5, 23, 18, 30, 0)\n",
    ">>> et = UTCDateTime(2014, 5, 23, 19, 40, 0)\n",
    ">>> st.plot(color='red', number_of_ticks=7,\n",
    "                   tick_rotation=5, tick_format='%I:%M %p',\n",
    "                   starttime=dt, endtime=et)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = UTCDateTime(2014, 5, 23, 18, 30, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "et = UTCDateTime(2014, 5, 23, 19, 40, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "st.plot(color='red', number_of_ticks=7,\n",
    "                   tick_rotation=5, tick_format='%I:%M %p',\n",
    "                   starttime=dt, endtime=et)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 预处理：窗口化、去趋势标准化\n",
    "#### 该部分用到的部分函数在preprocess.py中\n",
    "- 窗口化：从连续波形中按特定时长截取地震事件或者背景噪声的窗口，每一个窗口对应一个标签，是模型训练集的一个样本。\n",
    "- 去趋势标准化：将截取的原始波形进行去趋势和归一化。\n",
    "\n",
    "主要函数有：\n",
    "\n",
    "- 根据目录和地震到时输出地震事件波形的初始时间\n",
    "```\n",
    "cat = read_catalog_orig(filename,arriving_time)\n",
    "filename为地震目录，arriving_time为地震到时\n",
    "```\n",
    "- 输出背景噪声窗口化的初始时间\n",
    "```\n",
    "cat = noise_train_orig()\n",
    "```\n",
    "- 根据地震理论到时从波形文件中截取波形，并标准化\n",
    "```\n",
    "streams_slice(st,arrival_time)\n",
    "st为连续波形Stream对象，arrival_time为地震到时\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 根据目录和地震到时输出地震事件波形的起始时间\n",
    "\n",
    "cat = read_catalog_orig(filename,arriving_time)\n",
    "# filename为地震目录，arriving_time为地震到时\n",
    "\n",
    "# 采用时间偏移方法的数据扩增\n",
    "# cat = read_catalog_ex4(filename,arriving_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 输出背景噪声窗口化的初始时间\n",
    "\n",
    "cat = noise_train_orig()\n",
    "\n",
    "# 采用时间偏移方法的数据扩增\n",
    "# cat = noise_train_ex4()\n",
    "\n",
    "# 测试集背景噪声窗口化的初始时间\n",
    "# cat = noise_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 根据窗口起始时间截取数据，并进行标准化\n",
    "\n",
    "# 地震目录\n",
    "catlogname = r'F:\\PythonProjects\\conv_for_quake\\yj_catlog\\week1.txt'\n",
    "# 输出地震事件窗口初始时间列表\n",
    "RHT_e = read_catalog_orig(catlogname,arriving_time)\n",
    "# 输出背景噪声窗口初始时间列表\n",
    "RHT_n = noise_train_orig()\n",
    "\n",
    "# 地震事件所在的连续波形文件\n",
    "wavename_rht = r'F:\\PythonProjects\\conv_for_quake\\yj_data\\20140524-30.RHT.mseed'\n",
    "# 背景噪声所在的连续波形文件\n",
    "noisename_rht = r'F:\\PythonProjects\\conv_for_quake\\yj_data\\20140523-24.RHT.mseed'\n",
    "\n",
    "# 新建用于存放地震事件和背景噪声窗口文件的空表\n",
    "Data_e = []\n",
    "Data_n = []\n",
    "\n",
    "# 根据地震事件初试时间列表和连续波形文件，从波形中截取窗口，并进行标准化\n",
    "st = read(wavename_rht)\n",
    "\n",
    "for i in RHT_e:\n",
    "    data = streams_slice(st,i)\n",
    "    Data_e.append(data)\n",
    "    \n",
    "Data_e = np.array(Data_e)\n",
    "Data_e.shape\n",
    "\n",
    "# 根据背景噪声初试时间列表和连续波形文件，从波形中截取窗口，并进行标准化\n",
    "nt = read(noisename_rht)\n",
    "\n",
    "for i in RHT_n:\n",
    "    data = streams_slice(nt,i)\n",
    "    Data_n.append(data)\n",
    "    \n",
    "Data_n = np.array(Data_n)\n",
    "Data_n.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据储存\n",
    "\n",
    "##### 把截取的窗口化地震事件和背景噪声数据储存到文件中\n",
    "\n",
    "本版本提供了储存到h5文件的功能，需要安装h5py扩展包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 将窗口化数据储存到.h5文件中\n",
    "\n",
    "with h5py.File(r'RHT.h5','a') as f:\n",
    "    f.create_dataset('event',data = Data_e)\n",
    "    f.create_dataset('noise',data = Data_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 读取.h5文件中的数据\n",
    "\n",
    "dataset = h5py.File(r'RFT.h5', \"r\")\n",
    "event_orig = np.array(dataset[\"event\"][:])\n",
    "nosie_orig = np.array(dataset[\"noise\"][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取压缩的文本格式数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path为压缩文件所在文件夹路径\n",
    "path = r\"F:\\PythonProjects\\wavelets\\ZJ\"\n",
    "\n",
    "files= os.listdir(path)\n",
    "# 通过files可以查看文件夹下压缩文件的文件名\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下分为两部分功能，一部分为读取数据归一化并存入h5文件，一部分为读取文件并绘图展示\n",
    "根据不同需要选择执行代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读取数据、归一化、存入h5文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 读取zip压缩文件中的数据并进行归一化\n",
    "\n",
    "data = []\n",
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "for i in np.arange(2,len(files)):\n",
    "    \n",
    "    read_hey = zipfile.ZipFile(files[i])\n",
    "\n",
    "    f1 = read_hey.open(r'ZJ_HL_BHN_0.txt','r')\n",
    "    f2 = read_hey.open(r'ZJ_HL_BHE_1.txt','r')\n",
    "    f3 = read_hey.open(r'ZJ_HL_BHZ_2.txt','r')\n",
    "    \n",
    "    nn = []\n",
    "    for line in f1.readlines():\n",
    "        line = line.decode()\n",
    "        lines = line.rstrip('\\r\\n')\n",
    "        lines = lines.encode()\n",
    "        nn.append(lines)\n",
    "    nn = np.array(nn)\n",
    "    nn = nn.reshape((-1,1))\n",
    "\n",
    "    ne = []\n",
    "    for line in f2.readlines():\n",
    "        line = line.decode()\n",
    "        lines = line.rstrip('\\r\\n')\n",
    "        lines = lines.encode()\n",
    "        ne.append(lines)\n",
    "    ne = np.array(ne)\n",
    "    ne = ne.reshape((-1,1))\n",
    "\n",
    "    nz = []\n",
    "    for line in f3.readlines():\n",
    "        line = line.decode()\n",
    "        lines = line.rstrip('\\r\\n')\n",
    "        lines = lines.encode()\n",
    "        nz.append(lines)\n",
    "    nz = np.array(nz)\n",
    "    nz = nz.reshape((-1,1))\n",
    "    \n",
    "    # 进行数据归一化\n",
    "    nn_minmax = min_max_scaler.fit_transform(nn)\n",
    "    ne_minmax = min_max_scaler.fit_transform(ne)\n",
    "    nz_minmax = min_max_scaler.fit_transform(nz)\n",
    "    \n",
    "    nn_minmax = nn_minmax.reshape((-1,))\n",
    "    ne_minmax = ne_minmax.reshape((-1,))\n",
    "    nz_minmax = nz_minmax.reshape((-1,))\n",
    "    \n",
    "    n = np.stack((nn_minmax,ne_minmax,nz_minmax), axis=1)\n",
    "    \n",
    "    data.append(n)\n",
    "\n",
    "DATA = np.stack(data, axis=0)\n",
    "DATA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 把数据存入文件\n",
    "with h5py.File(r'HL_event.h5','a') as f:\n",
    "    f.create_dataset('event',data = DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读取文件，并绘图展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 波形绘图\n",
    "read_hey = zipfile.ZipFile(files[13])\n",
    "\n",
    "f1 = read_hey.open(r'ZJ_HL_BHN_0.txt','r')\n",
    "f2 = read_hey.open(r'ZJ_HL_BHE_1.txt','r')\n",
    "f3 = read_hey.open(r'ZJ_HL_BHZ_2.txt','r')\n",
    "\n",
    "n1 = []\n",
    "for line in f1.readlines():\n",
    "    line = line.decode()\n",
    "    n1.append(line.rstrip('\\r\\n'))\n",
    "n1 = np.array(n1)\n",
    "n1 = n1.reshape((-1,1))\n",
    "\n",
    "n2 = []\n",
    "for line in f2.readlines():\n",
    "    line = line.decode()\n",
    "    n2.append(line.rstrip('\\r\\n'))\n",
    "n2 = np.array(n2)\n",
    "n2 = n2.reshape((-1,1))\n",
    "\n",
    "n3 = []\n",
    "for line in f3.readlines():\n",
    "    line = line.decode()\n",
    "    n3.append(line.rstrip('\\r\\n'))\n",
    "n3 = np.array(n3)\n",
    "n3 = n3.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 进行数据归一化\n",
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1))\n",
    "n1_minmax = min_max_scaler.fit_transform(n1)\n",
    "n2_minmax = min_max_scaler.fit_transform(n2)\n",
    "n3_minmax = min_max_scaler.fit_transform(n3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "plt.subplot(311)\n",
    "plt.plot(n1_minmax)\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.plot(n2_minmax)\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.plot(n3_minmax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
